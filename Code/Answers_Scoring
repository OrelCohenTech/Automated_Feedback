<<<<<<< HEAD
# 1. Imports and setup
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline


# 2. Load the dataset
print("Loading dataset...")
ds = load_dataset("nkazi/MohlerASAG")

# take a few examples
example1 = ds["train"][0]
example2 = ds["train"][1]
example3 = ds["train"][2]


# 3. Format examples

def make_input(example):
    return (
        "QUESTION: " + example["question"] + "\n"
        "CORRECT ANSWER: " + example["reference_answer"] + "\n"
        "STUDENT ANSWER: " + example["student_answer"]
    )

inputs = [
    make_input(example1),
    make_input(example2),
    make_input(example3),
]


# 4. Load a HuggingFace model (example: DistilBERT)
print("Loading model...")
model_name = "sentence-transformers/all-MiniLM-L6-v2"

classifier = pipeline(
    "text-classification",
    model=model_name,
    top_k=None
)


# 5. Inference on examples
print("\nRunning inference...")
for i, text in enumerate(inputs):
    print(f"\n--- Example {i+1} ---")
    result = classifier(text)
    print(result)
=======

>>>>>>> c96806680b99ac92bce1e5f94ffab44b29850f07
